{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdkOuI7P36J6zlH3DxzlRd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rJBWMRO1CHU1"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_c, out_c, kernel_size=3, padding=1):\n","        super().__init__()\n","\n","        self.layers = nn.Sequential(\n","            nn.Conv2d(in_c, out_c, kernel_size=kernel_size, padding=padding),\n","            nn.BatchNorm2d(out_c),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","\n","class DeconvBlock(nn.Module):\n","    def __init__(self, in_c, out_c):\n","        super().__init__()\n","\n","        self.deconv = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n","\n","    def forward(self, x):\n","        return self.deconv(x)\n","\n","\n","class UNETR_2D(nn.Module):\n","    def __init__(self, cf):\n","        super().__init__()\n","        self.cf = cf\n","\n","        \"\"\" Patch + Position Embeddings \"\"\"\n","        self.patch_embed = nn.Linear(\n","            cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"],\n","            cf[\"hidden_dim\"]\n","        )\n","\n","        self.positions = torch.arange(start=0, end=cf[\"num_patches\"], step=1, dtype=torch.int32)\n","        self.pos_embed = nn.Embedding(cf[\"num_patches\"], cf[\"hidden_dim\"])\n","\n","        \"\"\" Transformer Encoder \"\"\"\n","        self.trans_encoder_layers = []\n","\n","        for i in range(cf[\"num_layers\"]):\n","            layer = nn.TransformerEncoderLayer(\n","                d_model=cf[\"hidden_dim\"],\n","                nhead=cf[\"num_heads\"],\n","                dim_feedforward=cf[\"mlp_dim\"],\n","                dropout=cf[\"dropout_rate\"],\n","                activation=nn.GELU(),\n","                batch_first=True\n","            )\n","            self.trans_encoder_layers.append(layer)\n","\n","        \"\"\" CNN Decoder \"\"\"\n","        ## Decoder 1\n","        self.d1 = DeconvBlock(cf[\"hidden_dim\"], 512)\n","        self.s1 = nn.Sequential(\n","            DeconvBlock(cf[\"hidden_dim\"], 512),\n","            ConvBlock(512, 512)\n","        )\n","        self.c1 = nn.Sequential(\n","            ConvBlock(512+512, 512),\n","            ConvBlock(512, 512)\n","        )\n","\n","        ## Decoder 2\n","        self.d2 = DeconvBlock(512, 256)\n","        self.s2 = nn.Sequential(\n","            DeconvBlock(cf[\"hidden_dim\"], 256),\n","            ConvBlock(256, 256),\n","            DeconvBlock(256, 256),\n","            ConvBlock(256, 256)\n","        )\n","        self.c2 = nn.Sequential(\n","            ConvBlock(256+256, 256),\n","            ConvBlock(256, 256)\n","        )\n","\n","        ## Decoder 3\n","        self.d3 = DeconvBlock(256, 128)\n","        self.s3 = nn.Sequential(\n","            DeconvBlock(cf[\"hidden_dim\"], 128),\n","            ConvBlock(128, 128),\n","            DeconvBlock(128, 128),\n","            ConvBlock(128, 128),\n","            DeconvBlock(128, 128),\n","            ConvBlock(128, 128)\n","        )\n","        self.c3 = nn.Sequential(\n","            ConvBlock(128+128, 128),\n","            ConvBlock(128, 128)\n","        )\n","\n","        ## Decoder 4\n","        self.d4 = DeconvBlock(128, 64)\n","        self.s4 = nn.Sequential(\n","            ConvBlock(3, 64),\n","            ConvBlock(64, 64)\n","        )\n","        self.c4 = nn.Sequential(\n","            ConvBlock(64+64, 64),\n","            ConvBlock(64, 64)\n","        )\n","\n","        \"\"\" Output \"\"\"\n","        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n","\n","    def forward(self, inputs):\n","        \"\"\" Patch + Position Embeddings \"\"\"\n","        patch_embed = self.patch_embed(inputs)   ## [8, 256, 768]\n","\n","        positions = self.positions\n","        pos_embed = self.pos_embed(positions)   ## [256, 768]\n","\n","        x = patch_embed + pos_embed ## [8, 256, 768]\n","\n","        \"\"\" Transformer Encoder \"\"\"\n","        skip_connection_index = [3, 6, 9, 12]\n","        skip_connections = []\n","\n","        for i in range(self.cf[\"num_layers\"]):\n","            layer = self.trans_encoder_layers[i]\n","            x = layer(x)\n","\n","            if (i+1) in skip_connection_index:\n","                skip_connections.append(x)\n","\n","        \"\"\" CNN Decoder \"\"\"\n","        z3, z6, z9, z12 = skip_connections\n","\n","        ## Reshaping\n","        batch = inputs.shape[0]\n","        z0 = inputs.view((batch, self.cf[\"num_channels\"], self.cf[\"image_size\"], self.cf[\"image_size\"]))\n","\n","        shape = (batch, self.cf[\"hidden_dim\"], self.cf[\"patch_size\"], self.cf[\"patch_size\"])\n","        z3 = z3.view(shape)\n","        z6 = z6.view(shape)\n","        z9 = z9.view(shape)\n","        z12 = z12.view(shape)\n","\n","\n","        ## Decoder 1\n","        x = self.d1(z12)\n","        s = self.s1(z9)\n","        x = torch.cat([x, s], dim=1)\n","        x = self.c1(x)\n","\n","        ## Decoder 2\n","        x = self.d2(x)\n","        s = self.s2(z6)\n","        x = torch.cat([x, s], dim=1)\n","        x = self.c2(x)\n","\n","        ## Decoder 3\n","        x = self.d3(x)\n","        s = self.s3(z3)\n","        x = torch.cat([x, s], dim=1)\n","        x = self.c3(x)\n","\n","        ## Decoder 4\n","        x = self.d4(x)\n","        s = self.s4(z0)\n","        x = torch.cat([x, s], dim=1)\n","        x = self.c4(x)\n","\n","        \"\"\" Output \"\"\"\n","        output = self.output(x)\n","\n","        return output"]},{"cell_type":"code","source":["\"\"\" Parts of the U-Net Model\"\"\"\n","\n","class ConvBlock(nn.Module):\n","    \"\"\"(Convolution => [BN] ==> ReLU) * 2\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","\n","        self.convblock = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.convblock(x)\n","\n","class Encoder(nn.Module):\n","    \"\"\"Downscaling with maxpool then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            ConvBlock(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","\n","class Decoder(nn.Module):\n","    \"\"\"Upscaling then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","\n","        # If bilinear, use the normal convolutions to reduce the number of channels\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","            self.conv - ConvBlock(in_channels, out_channels, in_channels//2)\n","\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = ConvBlock(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        # Input is CHW\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False):\n","        super(UNet,self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = ConvBlock(n_channels, 64)\n","        self.down1 = Encoder(64, 128)\n","        self.down2 = Encoder(128, 256)\n","        self.down3 = Encoder(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Encoder(512, 1024 // factor)\n","        self.up1 = Decoder(1024, 512 // factor, bilinear)\n","        self.up2 = Decoder(512, 256 // factor, bilinear)\n","        self.up3 = Decoder(256, 128 // factor, bilinear)\n","        self.up4 = Decoder(128, 64, bilinear)\n","        self.outc = OutConv(64, n_classes)\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits\n","\n","    def use_checkpointing(self):\n","        self.inc = torch.utils.checkpoint(self.inc)\n","        self.down1 = torch.utils.checkpoint(self.down1)\n","        self.down2 = torch.utils.checkpoint(self.down2)\n","        self.down3 = torch.utils.checkpoint(self.down3)\n","        self.down4 = torch.utils.checkpoint(self.down4)\n","        self.up1 = torch.utils.checkpoint(self.up1)\n","        self.up2 = torch.utils.checkpoint(self.up2)\n","        self.up3 = torch.utils.checkpoint(self.up3)\n","        self.up4 = torch.utils.checkpoint(self.up4)\n","        self.outc = torch.utils.checkpoint(self.outc)\n"],"metadata":{"id":"e7loQYwICPbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# === Basic ConvBlock ===\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","\n","        self.convblock = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.convblock(x)\n","\n","# === Encoder ===\n","class Encoder(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            ConvBlock(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","# === Decoder ===\n","class Decoder(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","            self.conv = ConvBlock(in_channels, out_channels, in_channels // 2)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = ConvBlock(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","# === Output Layer ===\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","# === Transformer Block ===\n","class TransformerBlock(nn.Module):\n","    def __init__(self, dim, num_heads, mlp_dim, dropout=0.1):\n","        super().__init__()\n","        self.norm1 = nn.LayerNorm(dim)\n","        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, dropout=dropout, batch_first=True)\n","        self.norm2 = nn.LayerNorm(dim)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(dim, mlp_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(mlp_dim, dim),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        x2 = self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n","        x = x + x2\n","        x2 = self.mlp(self.norm2(x))\n","        x = x + x2\n","        return x\n","\n","# === Transformer Encoder ===\n","class TransformerEncoder(nn.Module):\n","    def __init__(self, in_channels, patch_size=16, dim=512, depth=4, heads=8, mlp_dim=1024):\n","        super().__init__()\n","        self.patch_size = patch_size\n","        self.dim = dim\n","        self.proj = nn.Conv2d(in_channels, dim, kernel_size=patch_size, stride=patch_size)\n","        self.transformer = nn.Sequential(\n","            *[TransformerBlock(dim, heads, mlp_dim) for _ in range(depth)]\n","        )\n","\n","    def forward(self, x):\n","        B, C, H, W = x.shape\n","        x = self.proj(x)  # (B, dim, H/P, W/P)\n","        x = x.flatten(2).transpose(1, 2)  # (B, N, dim)\n","        x = self.transformer(x)\n","        x = x.transpose(1, 2).reshape(B, self.dim, H // self.patch_size, W // self.patch_size)\n","        return F.interpolate(x, size=(H, W), mode='bilinear', align_corners=False)\n","\n","# === TransUNet ===\n","class TransUNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False):\n","        super(TransUNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = ConvBlock(n_channels, 64)\n","        self.down1 = Encoder(64, 128)\n","        self.down2 = Encoder(128, 256)\n","        self.down3 = Encoder(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Encoder(512, 1024 // factor)\n","\n","        self.transformer = TransformerEncoder(1024 // factor, patch_size=16, dim=512, depth=4, heads=8, mlp_dim=1024)\n","\n","        self.up1 = Decoder(1024, 512 // factor, bilinear)\n","        self.up2 = Decoder(512, 256 // factor, bilinear)\n","        self.up3 = Decoder(256, 128 // factor, bilinear)\n","        self.up4 = Decoder(128, 64, bilinear)\n","        self.outc = OutConv(64, n_classes)\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x5 = self.transformer(x5)\n","\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits\n"],"metadata":{"id":"oxcF-0gnExBs"},"execution_count":null,"outputs":[]}]}